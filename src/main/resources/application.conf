
kafka-dispatcher {
  type = Dispatcher
  executor = "thread-pool-executor"
  thread-pool-executor {
    fixed-pool-size = 5
  }
  throughput = 100
}


akka.http.parsing.max-chunk-size = 16m
akka.http.client.parsing.max-content-length = 20m
logger {
  # Set the log level for Kafka components to INFO
  "org.apache.kafka" = INFO
  "akka.kafka" = INFO
  "akka.stream.kafka" = INFO

  # Optionally, set other components to DEBUG if needed
  # "your.application.package" = DEBUG
}
akka {
  loglevel = "INFO"
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  stdout-loglevel = "INFO"
  actor {
    deployment {
      /exampleActor {
        router = round-robin-pool
        nr-of-instances = 3
      }

    }

    default-dispatcher {
      type = "Dispatcher"
      executor = "thread-pool-executor"
      name = "cao-default-dispatcher"
      thread-pool-executor {
        core-pool-size-min = 10
        core-pool-size-max = 10
      }
      throughput = 100
    }
  }


  http {
    server {
      request-timeout = 60s
      pipelining-limit = 100
      idle-timeout = 240s
      backlog = 100
    }
  }

  kafka {
    consumer {
      poll-interval = 1s
      poll-timeout = 1s
      use-dispatcher = "kafka-dispatcher"
      wakeup-timeout = 25s
      max-wakeups = 50
      kafka-clients {
        enable.auto.commit = false
        session.timeout.ms = 35000
        heartbeat.interval.ms = 30000
        auto.commit.interval.ms = 5000
        max.poll.records = 80000
        receive.buffer.bytes = 102400000
        max.partition.fetch.bytes = 81920000
        fetch.min.bytes = 180000
      }
    }
  }
}

kamon {
  environment.service = "manoj-demo"
}


kamon.propagation.http.default.tags {
  mappings {
    requestID = "X-Request-ID"
  }
}

//kamon.zipkin {
//
//  # Hostname and port where the Zipkin Server is running
//  #
//  host = "localhost"
//  port = 9411
//
//  # Decides whether to use HTTP or HTTPS when connecting to Zipkin
//  protocol = "http"
//}
//kamon.trace.join-remote-parents-with-same-span-id = yes